{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE >\n",
      "<html lang=\"en\">\n",
      "<head>\n",
      "<title>\n",
      "            First Web Page\n",
      "        </title>\n",
      "<meta charset=\"utf-8\"/>\n",
      "<meta content=\"PyTech 2.0 Foundation\" name=\"author\"/>\n",
      "</head>\n",
      "<body>\n",
      "<header>\n",
      "<h1>\n",
      "                Test Website\n",
      "            </h1>\n",
      "</header>\n",
      "<div class=\"article\">\n",
      "<h2>\n",
      "                Article 1 Headline\n",
      "            </h2>\n",
      "<p>\n",
      "                This is a summary of the article 1\n",
      "            </p>\n",
      "</div>\n",
      "<div class=\"article\">\n",
      "<h2>\n",
      "                Article 2 Headline\n",
      "            </h2>\n",
      "<p>\n",
      "                This is a summary of the article 2\n",
      "            </p>\n",
      "</div>\n",
      "<div class=\"article\">\n",
      "<h2>\n",
      "                Article 3 Headline\n",
      "            </h2>\n",
      "<p>\n",
      "                This is a summary of the article 3\n",
      "            </p>\n",
      "</div>\n",
      "<div class=\"footer\">\n",
      "<p>\n",
      "                Footer Information\n",
      "            </p>\n",
      "</div>\n",
      "</body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Parsing a basic html file using xml parser\n",
    "with open('index.html') as html_file:\n",
    "    soup = BeautifulSoup(html_file, 'lxml')\n",
    "print(soup)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE >\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   First Web Page\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"PyTech 2.0 Foundation\" name=\"author\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <header>\n",
      "   <h1>\n",
      "    Test Website\n",
      "   </h1>\n",
      "  </header>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 1 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 1\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 2 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 2\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 3 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 3\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"footer\">\n",
      "   <p>\n",
      "    Footer Information\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#To get a more clear visualization of the data we can use the prettify method\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE >\n",
      "<html lang=\"en\">\n",
      " <head>\n",
      "  <title>\n",
      "   First Web Page\n",
      "  </title>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"PyTech 2.0 Foundation\" name=\"author\"/>\n",
      " </head>\n",
      " <body>\n",
      "  <header>\n",
      "   <h1>\n",
      "    Test Website\n",
      "   </h1>\n",
      "  </header>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 1 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 1\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 2 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 2\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"article\">\n",
      "   <h2>\n",
      "    Article 3 Headline\n",
      "   </h2>\n",
      "   <p>\n",
      "    This is a summary of the article 3\n",
      "   </p>\n",
      "  </div>\n",
      "  <div class=\"footer\">\n",
      "   <p>\n",
      "    Footer Information\n",
      "   </p>\n",
      "  </div>\n",
      " </body>\n",
      "</html>\n"
     ]
    }
   ],
   "source": [
    "#We can also use the html5 parser to parse the html file\n",
    "with open('index.html') as html_file:\n",
    "    soup = BeautifulSoup(html_file, 'html5lib') #Using html5 file parser\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<title>\n",
      "            First Web Page\n",
      "        </title>\n"
     ]
    }
   ],
   "source": [
    "#Now if we want to get the information in the title tag \n",
    "match = soup.title\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "            First Web Page\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "#Now if we only want to get the text of the title tag\n",
    "match = soup.title.text\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"article\">\n",
      "            <h2>\n",
      "                Article 1 Headline\n",
      "            </h2>\n",
      "            <p>\n",
      "                This is a summary of the article 1\n",
      "            </p>\n",
      "        </div>\n"
     ]
    }
   ],
   "source": [
    "#If we use the tag attribute method, it always gives us the information regarding the first appearance of the tag in the file\n",
    "match = soup.div\n",
    "print(match)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<div class=\"article\">\n",
      "            <h2>\n",
      "                Article 1 Headline\n",
      "            </h2>\n",
      "            <p>\n",
      "                This is a summary of the article 1\n",
      "            </p>\n",
      "        </div>\n"
     ]
    }
   ],
   "source": [
    "#In case we have to find a particular tag value, we can use the find method to find it\n",
    "article = soup.find('div', class_ = 'article')\n",
    "print(article)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Article 1 Headline\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#Now if we want to get only the text of header of the article\n",
    "header = article.h2.text\n",
    "print(header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                This is a summary of the article 1\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#Now if we want to get only the text of summary of the article\n",
    "summary = article.p.text\n",
    "print(summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Article 1 Headline\n",
      "            \n",
      "\n",
      "                This is a summary of the article 1\n",
      "            \n",
      "\n",
      "                Article 2 Headline\n",
      "            \n",
      "\n",
      "                This is a summary of the article 2\n",
      "            \n",
      "\n",
      "                Article 3 Headline\n",
      "            \n",
      "\n",
      "                This is a summary of the article 3\n",
      "            \n"
     ]
    }
   ],
   "source": [
    "#Suppose we want to get the headers and summaries of all the articles, then:\n",
    "for article in soup.find_all('div', class_ = 'article'):\n",
    "    header = article.h2.text\n",
    "    print(header)\n",
    "    summary = article.p.text\n",
    "    print(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
